#!/usr/bin/env python

import sys
import os
import argparse
from collections import defaultdict
import altair as alt
import pandas as pd
import numpy as np

sys.path.append("/net/bbi/vol1/data/sge-analysis/lib/")
import sge_util
import sge_counts
import sge_altair
import sge_target


def saveSNVScoreFigure(plotdf, args):
    overallmax = np.nanmax(plotdf[np.isfinite(plotdf[["log2ratio_recentered", "log2ratio"]])][["log2ratio_recentered", "log2ratio"]])
    overallmin = np.nanmin(plotdf[np.isfinite(plotdf[["log2ratio_recentered", "log2ratio"]])][["log2ratio_recentered", "log2ratio"]])

    scorecol = alt.binding_select(
        options=['log2ratio', 'log2ratio_recentered'],
        name='Score type',
        labels=['raw', 'recentered']
    )
    ycol_param = alt.param(
        value='log2ratio',
        bind=scorecol
    )

    day_dropdown = alt.binding_select(options=days, name='Day ', )
    day_selection = alt.selection_point(fields=['day'], 
                                    bind=day_dropdown, value=days[0])

    repl_dropdown = alt.binding_select(options=repls + ["mean", "median"], name='Replicate ', )
    repl_selection = alt.selection_point(fields=['repl'], 
                                    bind=repl_dropdown, value="median")

    selection = (repl_selection & day_selection)
    brush = alt.selection_interval(encodings=['x'])
    consequence_selection = alt.selection_point(fields=['Consequence'], bind='legend')

    a = alt.Chart(plotdf, height=200, width=1200).mark_point(filled=True, size=50).encode(
        x=alt.X('pos:N', title="Position" ,sort='x', axis=alt.Axis(labelFontSize=10)
    ),
        y=alt.Y('y:Q', title="log2 ratio", scale=alt.Scale()),
        color=alt.Color('Consequence:N', title="Variant type"),
        opacity=alt.condition(consequence_selection, alt.value(1), alt.value(0.2)),
        tooltip=['pos', 'mutant_allele', 'ref', 'posid','Consequence', 'log2ratio', 'log2ratio_recentered']
    ).transform_filter(
        selection
    ).transform_calculate(
        y=f'datum[{ycol_param.name}]'
    ).add_params(
        repl_selection, day_selection, consequence_selection, brush, ycol_param
    ).interactive()

    b = alt.Chart(plotdf, width=550, height=250
            ).mark_bar(
        opacity=0.9,
        binSpacing=0
    ).encode(
        x=alt.X('y:Q', title="log2 ratio", 
            axis=alt.Axis(labelFontSize=12, labelAngle=315)).bin(extent=[overallmin, overallmax], step=0.1),
        y=alt.Y('count()', title="number of variants").stack("zero"),
        color=alt.Color('Consequence:N', title="Variant type", scale=alt.Scale(scheme="category10"))
    ).transform_filter(
        selection
    ).transform_filter(
        brush
    ).transform_calculate(
        y=f'datum[{ycol_param.name}]'
    ).add_params(
        repl_selection, day_selection, ycol_param
    )

    c = alt.Chart(plotdf, width=550, height=250
            ).mark_bar(
        opacity=0.9,
        binSpacing=0
    ).encode(
        x=alt.X('y:Q', title="log2 ratio", 
            axis=alt.Axis(labelFontSize=12, labelAngle=315)).bin(extent=[overallmin, overallmax], step=0.1),
        y=alt.Y('count()', title="Distribution within score bin").stack("normalize"),
        color=alt.Color('Consequence:N', title="Variant type", scale=alt.Scale(scheme="category10"))
    ).transform_filter(
        selection
    ).transform_filter(
        brush
    ).transform_calculate(
        y=f'datum[{ycol_param.name}]'
    ).add_params(
        repl_selection, day_selection, ycol_param
    )

    scorechart = (a & (b | c)).properties(title="log2 ratio scores for %s" % exonname).configure_title(fontSize=20, 
                    offset=5, 
                    orient='top', 
                    anchor='middle',
    )
    scorechart.save("viz/%s.scores.html" % exonname)
    return


def scoreDels(args, scoreall=True):
    '''compute scores for the 3bp programmed deletions
    
    '''
    chrom, startpos, endpos = sge_util.getTargetEditRegion(args.targetfile, args.targetname)
    skip_pos = sge_util.getTargetSkipPositions(args.targetfile, args.targetname)
    req_edits = sge_util.getTargetRequiredEdits(args.targetfile, args.targetname)

    # read deletion counts files
    deldf = pd.DataFrame()
    delfiles = sge_counts.getAllDelCountFiles(args.targetname,
                                              args.countsdir,
                                              filterstring="NC_")
    for delfile in delfiles:
        tmpdf = sge_counts.getDelCounts(delfile, augment=True)
        if scoreall:
            tmpdf = addMissingDels(tmpdf, chrom, startpos, endpos)
        deldf = pd.concat([deldf, tmpdf])
    deldf = deldf.reset_index(drop=True)

    # read ReadStats files
    statsdf = pd.DataFrame()
    statsfiles = sge_counts.getAllReadStatsFiles(args.targetname,
                                                 args.countsdir,
                                                 filterstring="NC_")
    for statsfile in statsfiles:
        tmpdf = sge_counts.getReadStats(statsfile, augment=True)
        statsdf = pd.concat([statsdf, tmpdf])
    statsdf = statsdf.reset_index(drop=True)





def scoreSNVs(target, args):
    '''compute scores for SNVs
    
    '''
    # load the day 0 library
    snvfiles = target.getSampleList(args.countsdir,
                                    include_neg=False)
    libfile = snvfiles['D00'][0]
    df = sge_counts.getSNVCounts(libfile,
                                 augment=True,
                                 pseudocount=args.pseudocount)
    df = df.rename(columns={'count': 'snvlib_count'}
        ).drop(columns=["sampleid", "repl", "day"])
    statsfile = libfile.replace(".snvs.tsv", ".readstats.tsv")
    statsdf = sge_counts.getReadStats(statsfile, augment=False)
    normval = statsdf[args.normcol][0]
    df['snvlib_freq'] = df['snvlib_count'] / normval
        
    if args.verbose:
        print("INFO: Loaded data from SNV Day 0 library")

    # load the various timepoints and replicates
    nsamples = 1
    allrepls = {}

    for snvday, snvfilelist in sorted(snvfiles.items()):
        if snvday == "D00": continue  # already loaded
        allrepls[snvday] = []
        for snvfile in sorted(snvfilelist):
            # exclude neg
            if "_NC_" in snvfile:
                continue
            nsamples += 1
            if args.verbose:
                print("INFO: loading data from %s" % snvfile)
            tmpdf = sge_counts.getSNVCounts(snvfile,
                                            augment=False,
                                            pseudocount=args.pseudocount)
            statsfile = snvfile.replace(".snvs.tsv", ".readstats.tsv")
            statsdf = sge_counts.getReadStats(statsfile, augment=False)
            sampleid = tmpdf["sampleid"][0]
            parts = sampleid.split("_")
            repl = parts[2]
            allrepls[snvday].append(repl)
            countcol = "%s_%s" % (snvday, repl)
            tmpdf = tmpdf.rename(columns={'count': countcol})
            freqcol = countcol + "_freq"
            normval = statsdf[args.normcol][0]
            tmpdf[freqcol] = tmpdf[countcol] / normval
            df = df.merge(tmpdf[["chrom", "pos", "allele", countcol, freqcol]], on=["chrom", "pos", "allele"])
    if args.verbose:
        print("INFO: Finished loading data from %d samples" % nsamples)
        print("INFO: Found data from timepoints: ", list(allrepls.keys()))

    df = df[(df["pos"] >= target.editstartpos) &
            (df["pos"] <= target.editendpos)]
    # merge with the reference sequence
    df = df.merge(target.refdf, on="pos")
    df = df[df["ref"] != df["allele"]]
    df["pos_id"] = df["pos"].astype(str) + ":" + df["allele"]
    # pivot and annotate with metadata
    df["pam_edit_or_snp"] = False
    df.loc[df["pos"].isin(target.required_edits), "pam_edit_or_snp"] = True
    df.loc[df["pos"].isin(target.skip_pos), "pam_edit_or_snp"] = True

    # annotate with vep preditions
    vepdf = sge_util.getVEPdf(args.vepfile)
    df = df.merge(vepdf[["pos", "allele", "Consequence"]], 
                  on=["pos", "allele"]) 



    # now we have counts, frequencies, and annotations for each position and each sample.
    # next step is to convert them into scores
    for day, repls in sorted(allrepls.items()):
        for repl in repls:
            freqcol = "%s_%s_freq" % (day, repl)
            ratiocol = "%s_%s_over_lib" % (day, repl)
            df[ratiocol] = df[freqcol] / df['snvlib_freq']

    # we also need day 13 (or day 11) vs day 5, per replicate
    days = sorted(allrepls.keys())
    earlyday = days[0]
    lateday = days[1]
    for repl in allrepls[earlyday]:
        if repl in allrepls[lateday]:
            df["%s_%s_over_%s_%s" % (lateday, repl, earlyday, repl)] = \
                df["%s_%s_freq" % (lateday, repl)] / df["%s_%s_freq" % (earlyday, repl)]


    for day, repls in sorted(allrepls.items()):
        replcols = []
        for repl in repls:
            replcols.append("%s_%s_over_lib" % (day, repl))
        df["%s_over_lib_median" % day] = df[replcols].median(axis=1)
        df["%s_log2_median" % day] = np.log2(df["%s_over_lib_median" % day])

    return df


def saveSNVscores(args, scoredf):
    outfile = args.snvtsv
    scoredf.to_csv(outfile, index=False, sep="\t")
    if args.verbose:
        print("INFO: wrote SNV scores to %s" % outfile)
    return


def main():
    parser = argparse.ArgumentParser('extract matrix of edits for an SGE sample')
    parser.add_argument('-n', '--targetname', required=True,
                        help="Target name -- must match entry in <targetfile>")
    parser.add_argument('-t', '--targetfile', required=True, 
                        help="File containing list of targets and expected edits")
    parser.add_argument('-s', '--snvtsv', required=False, default="", 
                        help="Output TSV file of SNV scores")
    parser.add_argument('-S', '--snvfig', required=False, default="", 
                        help="Output figure of SNV scores")
    parser.add_argument('-d', '--deltsv', required=False, default="", 
                        help="Output TSV file of deletion scores")
    parser.add_argument('-D', '--delfig', required=False, default="", 
                        help="Output figure of deletion scores")
    parser.add_argument('-c', '--countsdir', required=True, default="",
                        help="Directory containing per-sample SNV counts files")
    parser.add_argument('-V', '--vepfile', required=True, default="",
                        help="output from Variant Effect Predictor for this target")
    parser.add_argument('-p', '--pseudocount', type=int, default=1, required=False,
                        help="add <pseudocount> to any zero-count position")
    parser.add_argument('-N', '--normcol', required=False, default="snv_reads",
                        help="Name of column in readstats file to use for normalization")
    
    parser.add_argument('-v', '--verbose', required=False, default=False,
                        action="store_true", help="Verbose output")
    args = parser.parse_args()

    target = sge_target.Target(args.targetname, args.targetfile)

    # SNV scoring
    if args.snvtsv:
        scoredf = scoreSNVs(target, args)
        saveSNVscores(args, scoredf)
    return 0


if __name__ == '__main__':
    main()
    
